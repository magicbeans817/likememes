{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook downloads data about globally top selling games from digital gaming platform Steam. These data contain title, release date and information about reviews and prices of individual games. Output of this Downloader is CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download a few packages necessary for our downloader to be able to scrape data from Steam webpage, then other packages help us display raw data and pandas help us to create the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a class, which we call 'Downloader'. Functions of few first attributes of this downloader come naturally from their names. Then we create attributes 'dataf', 'hoarder' and 'download_data'. As the list of games is too long for just one webpage, Steam saved it in more than 600 webpages in total. Thus, downloading our data works in following way, using  'download_data' attribute:\n",
    "- It begins by creating a list of urls of given number of pages (starting from the first one) using 'hoarder' attribute.\n",
    "- Then it uses 'dataf' attribute, which downloads HTML for every url in the list, applies first few attributes of class 'Downloader' and creates pandas dataframe of data for every given url.\n",
    "- Last, 'download_data' appends dataframe for every url to one large dataframe we want to end up with. It also assigns indexes to individual games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downloader:\n",
    "    def __init__(self, link):\n",
    "        self.link = link\n",
    "        self.uClient = uReq(link)\n",
    "        self.page_html = self.uClient.read()\n",
    "        self.uClient.close()\n",
    "        self.soup = BeautifulSoup(self.page_html, \"lxml\")\n",
    "        \n",
    "    \n",
    "    def get_titles(self):\n",
    "        td = self.soup.findAll('span', {\"class\":\"title\"})\n",
    "        titles = []\n",
    "        for ind in td:\n",
    "            # lstrip and rstrip remove symbols from sides, strip removes white spaces\n",
    "            try:\n",
    "                titles.append(str(ind).lstrip('<span class=\"title\">').rstrip('span>').rstrip('</'))\n",
    "            except:\n",
    "                titles.append(\"Title not available\")                \n",
    "        return titles\n",
    "    \n",
    "    def get_release_dates(self):\n",
    "        td = self.soup.findAll('div', {\"class\":\"col search_released responsive_secondrow\"})\n",
    "        release_dates = []\n",
    "        for ind in td:\n",
    "            if ind.text != \"\":\n",
    "            # lstrip and rstrip remove symbols from sides, strip removes white spaces\n",
    "                try:\n",
    "                    release_dates.append(str(ind).rstrip('</div>').split(\">\")[-1])\n",
    "                except:\n",
    "                    release_dates.append(None)\n",
    "            else:\n",
    "                release_dates.append(None)\n",
    "        return release_dates\n",
    "    \n",
    "    def reviews(self):\n",
    "        tds = self.soup.findAll('div', {\"class\":\"col search_reviewscore responsive_secondrow\"})\n",
    "        reviews = []\n",
    "        for td in tds:     \n",
    "            try:\n",
    "                children = td.findChildren('span', recursive=False)\n",
    "                for ind in children:\n",
    "                    # lstrip and rstrip remove symbols from sides, strip removes white spaces\n",
    "                    try:\n",
    "                        reviews.append(str(ind).split(\"html=\")[-1])\n",
    "                    except:\n",
    "                        reviews.append(None)\n",
    "            except:\n",
    "                reviews.append(None)\n",
    "        return reviews\n",
    "     \n",
    "    def get_share_positive_reviews(self):\n",
    "        text = self.reviews()\n",
    "        shares = []\n",
    "        for percent in text:\n",
    "            try:\n",
    "                shares.append(percent.split(\"%\")[0].split(\"br&gt;\")[1])\n",
    "            except:\n",
    "                shares.append(None)\n",
    "        return shares\n",
    "        \n",
    "    def get_number_user_reviews(self):  \n",
    "        text = self.reviews()\n",
    "        numbers = []\n",
    "        for number in text:\n",
    "            try:\n",
    "                start = number.find(\"of the \") + len(\"of the \")\n",
    "                end = number.find(\" user reviews\")\n",
    "                numbers.append(number[start:end].replace(\",\",\"\"))\n",
    "            except:\n",
    "                numbers.append(None)\n",
    "        return numbers\n",
    "        \n",
    "    def get_prices(self):\n",
    "\n",
    "        td = self.soup.findAll('div', {\"class\":\"col search_price_discount_combined responsive_secondrow\"} or \n",
    "                          {\"class\":\"col search_price discounted responsive_secondrow\"})\n",
    "        prices = []\n",
    "        for ind in td:\n",
    "            try:\n",
    "                if \"888888\" not in str(ind):\n",
    "                    try:\n",
    "                        if (len(str(ind).split(\"\\r\\n\")[-1].split(\"</div>\\n</div>\")[0].strip()) <10):    \n",
    "                            prices.append(str(ind).split(\"\\r\\n\")[-1].split(\"</div>\\n</div>\")[0].strip().replace(\"€\",\"\").replace(\",\",\".\").replace(\"-\",\"0\").replace(\"Free\",\"0\")) \n",
    "                        else:\n",
    "                            prices.append(None)\n",
    "                    except:\n",
    "                        prices.append(None)\n",
    "                else:\n",
    "                    start1 = str(ind).find(\"><strike>\") + len(\"><strike>\")\n",
    "                    end1 = str(ind).find(\"</strike>\")\n",
    "                    prices.append(str(ind)[start1:end1].replace(\"€\",\"\").replace(\",\",\".\").replace(\"-\",\"0\").replace(\"Free\",\"0\"))\n",
    "            except: \n",
    "                prices.append(None)\n",
    "        return prices\n",
    "    \n",
    "    def get_price_after_sale(self):\n",
    "\n",
    "        td = self.soup.findAll('div', {\"class\":\"col search_price_discount_combined responsive_secondrow\"} or \n",
    "                          {\"class\":\"col search_price discounted responsive_secondrow\"})\n",
    "        sales = []\n",
    "        for ind in td:\n",
    "            if \"888888\" not in str(ind):\n",
    "                sales.append(None)\n",
    "            else:\n",
    "                try:\n",
    "                    if len(str(ind).split(\"br/>\")[-1].split(\"€\")) < 10:\n",
    "                        sales.append(str(ind).split(\"br/>\")[-1].split(\"€\")[0].strip().replace(\",\",\".\").replace(\"-\",\"0\").replace(\"Free\",\"0\"))\n",
    "                    else:\n",
    "                        sales.append(\"0\")\n",
    "                except:\n",
    "                    sales.append(\"0\")\n",
    "        return sales\n",
    "    \n",
    "    \n",
    "    def get_rate_of_sale(self):\n",
    "\n",
    "        td = self.soup.findAll('div', {\"class\":\"col search_price_discount_combined responsive_secondrow\"} or \n",
    "                          {\"class\":\"col search_price discounted responsive_secondrow\"})\n",
    "        percent = []\n",
    "        for ind in td:\n",
    "            if \"888888\" not in str(ind):\n",
    "                percent.append(None)\n",
    "            else:\n",
    "                try:\n",
    "                    start = str(ind).find(\">\\n<span>-\")+len(\">\\n<span>-\")\n",
    "                    end = str(ind).find(\"%\")\n",
    "                    percent.append(str(ind)[start:end])\n",
    "                except:\n",
    "                    percent.append(None)\n",
    "        return percent\n",
    "    \n",
    "    def dataf(self):\n",
    "        titles = self.get_titles()\n",
    "        dates = self.get_release_dates()\n",
    "        share_reviews = self.get_share_positive_reviews()\n",
    "        number_reviews = self.get_number_user_reviews()\n",
    "        normal_prices = self.get_prices()\n",
    "        sale_price = self.get_price_after_sale()\n",
    "        sale_rate = self.get_rate_of_sale()\n",
    "        \n",
    "        \n",
    "        self.data = pd.DataFrame({\n",
    "             'Title': pd.Series(titles),\n",
    "             'Release date': pd.to_datetime(pd.Series(dates),format='%d %b, %Y', errors = 'coerce'),\n",
    "             'Share of positive reviews (in %)': pd.to_numeric(share_reviews, errors='coerce'),\n",
    "             'Total number of reviews': pd.to_numeric(number_reviews, errors='coerce'),\n",
    "             'Normal price (€)': pd.to_numeric(normal_prices, errors='coerce'),\n",
    "             'Discounted price if there is a sale (€)': pd.to_numeric(sale_price, errors='coerce'),\n",
    "             'Sale rate (in %)': pd.to_numeric(sale_rate, errors='coerce')})\n",
    "        return self.data\n",
    "     \n",
    "    def total_games(self):\n",
    "        total_games = int(self.soup.find('div', {\"class\":\"search_pagination_left\"}).text.split(\"of\")[1].strip())\n",
    "        return total_games\n",
    "    \n",
    "    def last_page(self):\n",
    "        last_page = int(np.ceil((self.total_games())/25))\n",
    "        return last_page\n",
    "            \n",
    "    def hoarder(self):\n",
    "        urls = [] \n",
    "        for i in range(self.last_page()):\n",
    "            urls.append(self.link + f\"&page={1+i}\")\n",
    "        return urls\n",
    "    \n",
    "    def download_data(self):\n",
    "        urls = self.hoarder()\n",
    "        Frame = pd.DataFrame()\n",
    "        for url in urls:\n",
    "            Frame = Frame.append(pd.DataFrame(data = Downloader(url).dataf()))\n",
    "        Frame.index = range(self.total_games())\n",
    "        return Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the link for Steam page of global top sellers ordered by reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://store.steampowered.com/search/?sort_by=Reviews_DESC&os=win&filter=globaltopsellers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the link in order to continue working with it. Next, we can apply the 'download_data' attribute and take a look at the craped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Share of positive reviews (in %)</th>\n",
       "      <th>Total number of reviews</th>\n",
       "      <th>Normal price (€)</th>\n",
       "      <th>Discounted price if there is a sale (€)</th>\n",
       "      <th>Sale rate (in %)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Witcher 3: Wild Hunt - Expansion Pass</td>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>99</td>\n",
       "      <td>3351</td>\n",
       "      <td>24.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Senren＊Banka</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>99</td>\n",
       "      <td>2854</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A Short Hike</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>99</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aseprite</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>99</td>\n",
       "      <td>2751</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Doki Doki Literature Club Fan Pack</td>\n",
       "      <td>2017-09-22</td>\n",
       "      <td>99</td>\n",
       "      <td>1498</td>\n",
       "      <td>9.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14473</td>\n",
       "      <td>Men of War: Assault Squad 2 - Cold War</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>17</td>\n",
       "      <td>539</td>\n",
       "      <td>21.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14474</td>\n",
       "      <td>Far Cry® 5 - Dead Living Zombies</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>17</td>\n",
       "      <td>585</td>\n",
       "      <td>7.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14475</td>\n",
       "      <td>Command &amp;amp; Conquer 4: Tiberian Twilight</td>\n",
       "      <td>2010-03-16</td>\n",
       "      <td>17</td>\n",
       "      <td>2340</td>\n",
       "      <td>19.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14476</td>\n",
       "      <td>Tom Clancy's Ghost Recon® Wildlands - Narco Road</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>16</td>\n",
       "      <td>501</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14477</td>\n",
       "      <td>Airport Simulator 2014</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>12</td>\n",
       "      <td>536</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2.99</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14478 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title Release date  \\\n",
       "0             The Witcher 3: Wild Hunt - Expansion Pass   2015-05-19   \n",
       "1                                          Senren＊Banka   2020-02-14   \n",
       "2                                          A Short Hike   2019-07-30   \n",
       "3                                              Aseprite   2016-02-22   \n",
       "4                    Doki Doki Literature Club Fan Pack   2017-09-22   \n",
       "...                                                 ...          ...   \n",
       "14473            Men of War: Assault Squad 2 - Cold War   2019-09-12   \n",
       "14474                  Far Cry® 5 - Dead Living Zombies   2018-08-28   \n",
       "14475        Command &amp; Conquer 4: Tiberian Twilight   2010-03-16   \n",
       "14476  Tom Clancy's Ghost Recon® Wildlands - Narco Road   2017-04-25   \n",
       "14477                            Airport Simulator 2014   2013-12-19   \n",
       "\n",
       "       Share of positive reviews (in %)  Total number of reviews  \\\n",
       "0                                    99                     3351   \n",
       "1                                    99                     2854   \n",
       "2                                    99                     2757   \n",
       "3                                    99                     2751   \n",
       "4                                    99                     1498   \n",
       "...                                 ...                      ...   \n",
       "14473                                17                      539   \n",
       "14474                                17                      585   \n",
       "14475                                17                     2340   \n",
       "14476                                16                      501   \n",
       "14477                                12                      536   \n",
       "\n",
       "       Normal price (€)  Discounted price if there is a sale (€)  \\\n",
       "0                 24.99                                      NaN   \n",
       "1                 29.99                                      NaN   \n",
       "2                  6.59                                      NaN   \n",
       "3                 14.99                                      NaN   \n",
       "4                  9.99                                      NaN   \n",
       "...                 ...                                      ...   \n",
       "14473             21.99                                      NaN   \n",
       "14474              7.99                                     3.99   \n",
       "14475             19.99                                      NaN   \n",
       "14476             14.99                                      NaN   \n",
       "14477              9.99                                     2.99   \n",
       "\n",
       "       Sale rate (in %)  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "14473               NaN  \n",
       "14474              50.0  \n",
       "14475               NaN  \n",
       "14476               NaN  \n",
       "14477              70.0  \n",
       "\n",
       "[14478 rows x 7 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = Downloader(link)\n",
    "#first.download() # in order to explore page html in a reasonable way, one can use online javascript beautifier, available at:\n",
    "# beautifier.io\n",
    "df = first.download_data()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data as CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the data as CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('steam_global_sellers_by_reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
